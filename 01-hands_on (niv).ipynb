{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "romsoc_hands_on_1_handout",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSE6Xk6x71gI",
        "colab_type": "text"
      },
      "source": [
        "# Hands-On Session No. 1\n",
        "## (Get to know PyTorch, Gradient Descent on Linear Regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYnvYDMrAaIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRg7T4x8aE9",
        "colab_type": "text"
      },
      "source": [
        "## Create Data\n",
        "\n",
        "1. Create an an array of x-values (range between 0 and 1).\n",
        "2. Choose some coefficient theta\n",
        "3. Create the y values: x-values multiplied by theta, plus some gaussian noise\n",
        "4. Plot x,y data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zyteipk8S0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# complete your code here\n",
        "\n",
        "# real_theta = ??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KsDxXu2_JZU",
        "colab_type": "text"
      },
      "source": [
        "## Goal\n",
        "\n",
        "Our loss function is:\n",
        "$$ L = \\frac{1}{2} \\Vert y - \\theta X \\Vert^2_2 $$\n",
        "\n",
        "Our goal is to solve for best $\\theta$ that describes the linear relation between the data (x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM4s6KJZ86zn",
        "colab_type": "text"
      },
      "source": [
        "## Optional: Solve for theta using normal equations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fmtxGvg898J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# complete your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQxRviVj9SGV",
        "colab_type": "text"
      },
      "source": [
        "## Solving using gradient descent\n",
        "\n",
        "1. compute the analytic gradient $\\frac{\\partial L}{\\partial \\theta}$\n",
        "2. solve for theta using gradient descent method\n",
        "3. change the gradient computation to that give by pytorch (instead of using the analytic one)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB8ApQT79ARB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "# theta = ?  # <-------- fill initial theta in ??\n",
        "\n",
        "plt.ion()\n",
        "plt.plot(X.squeeze().numpy(), y.squeeze().numpy(), '.b')\n",
        "graph = plt.plot(X.squeeze().numpy(), torch.zeros_like(X).squeeze().numpy(), 'r')[0]\n",
        "losss = []\n",
        "\n",
        "for i in range(T):  \n",
        "  # compute next theta using gradient descent\n",
        "  \n",
        "  \n",
        "  \n",
        "  # Next lines are for visualization (uncomment when you're ready)\n",
        "##########################################################################\n",
        "#   # plot intermediate\n",
        "#   loss = ?? ;   losss.append(loss.item())  # <------ fill loss in ??\n",
        "#   if i % 10 == 0:\n",
        "#     print('{}: loss: {:.3g} theta: {:.3g}'.format(i, loss.item(), theta))\n",
        "#     display.clear_output(wait=True)\n",
        "#     graph.set_ydata((theta * X).squeeze().numpy())\n",
        "\n",
        "#     display.display(plt.gcf())\n",
        "#     time.sleep(0.1)\n",
        "##########################################################################\n",
        "\n",
        "print('real theta: ', real_theta)\n",
        "print('found theta:', theta)\n",
        "\n",
        "# plt.figure(); plt.plot(range(len(losss)), losss, 'k')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOH27XJU9_Ha",
        "colab_type": "text"
      },
      "source": [
        "## Bonus Questions:\n",
        "\n",
        "\n",
        "(1) Add bias to data and solve for both theta and data using gradient descent (optional: using normal equations)\n",
        "\n",
        "(2a) Create data for some polynom of degree d. Solve for coefficients using gradient descent (optional: using normal equations). \n",
        "\n",
        "(2b) Create data with few samples (~5-10). What do you see for larger d?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKp9lUnh-8g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}